{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b40b98-b131-4af8-a447-b54ec02764c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_checkpoint = f\"data/Llama1B/checkpoint-52\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model, cache_dir=\"../resources/cache\").to(device)\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721943a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5:\n",
      "You are given a list of queries separated by new line. Your job is to answer with the query that is the most well-formed or well-structured query in terms of grammar, punctuations, or spelling errors.\n",
      "Q: How do you set the alarm on the prospirit watch ?\n",
      "The allies tried to regain access to the battle of Gallipoli ?\n",
      "What is scooter smith real phone number not a fake one ?\n",
      "Law of Supply and Demand defined ?\n",
      "A: \n",
      "\n",
      "Base Model Response:\n",
      "You are given a list of queries separated by new line. Your job is to answer with the query that is the most well-formed or well-structured query in terms of grammar, punctuations, or spelling errors.\n",
      "Q: How do you set the alarm on the prospirit watch?\n",
      "The allies tried to regain access to the battle of Gallipoli?\n",
      "What is scooter smith real phone number not a fake one?\n",
      "Law of Supply and Demand defined?\n",
      "A: 1. The watch is not well-structured or grammatically correct.\n",
      "B: 2. The battle of Gallipoli is not well-structured or grammatically correct.\n",
      "C: 3. The phone number is not well-structured or grammatically correct.\n",
      "D: 4. The law of supply and demand is not well-structured or grammatically correct.\n",
      "Answer: A\n",
      "The best answer is A\n",
      "\n",
      "Finetuned Model Response:\n",
      "You are given a list of queries separated by new line. Your job is to answer with the query that is the most well-formed or well-structured query in terms of grammar, punctuations, or spelling errors.\n",
      "Q: How do you set the alarm on the prospirit watch?\n",
      "The allies tried to regain access to the battle of Gallipoli?\n",
      "What is scooter smith real phone number not a fake one?\n",
      "Law of Supply and Demand defined?\n",
      "A: 1. The most well-structured query is \"How do you set the alarm on the prospirit watch?\"\n",
      "B: 2. The most well-structured query is \"What is scooter smith real phone number not a fake one?\"\n",
      "C: 3. The most well-structured query is \"Law of Supply and Demand defined?\"\n",
      "D: 4. The most well-structured query is \"Q: How do you set the alarm on the prospirit watch?\"\n",
      "Answer: D: 4. The most well-structured query is \"Q: How do you set the alarm on the prospirit watch?\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"argilla/dpo-mix-7k\")\n",
    "\n",
    "# Specify the number of prompts to process\n",
    "N = 5  # You can adjust this to the desired number of prompts\n",
    "\n",
    "# Process the first N prompts\n",
    "i =4\n",
    "# x = dataset['train'][i]\n",
    "# print(x)\n",
    "prompt = dataset[\"train\"][i][\"chosen\"][0][\"content\"]\n",
    "# chosen = dataset[\"trian\"][]\n",
    "# print(prompt)\n",
    "\n",
    "# Tokenize the prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Generate base model response\n",
    "base_output = base_model.generate(**inputs, max_length=512, do_sample=False)\n",
    "base_response = tokenizer.decode(base_output[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate finetuned model response\n",
    "ft_output = ft_model.generate(**inputs, max_length=512, do_sample=False)\n",
    "ft_response = tokenizer.decode(ft_output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the prompt and responses\n",
    "print(f\"Prompt {i + 1}:\\n{prompt}\\n\")\n",
    "print(f\"Base Model Response:\\n{base_response}\\n\")\n",
    "print(f\"Finetuned Model Response:\\n{ft_response}\\n\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4b362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
